{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a865b25-0629-48a4-8adc-663789357029",
   "metadata": {},
   "source": [
    "# Audio Classification with Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96278e4f-0619-4fd4-882c-4ae02430ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b66b111-6016-412d-92ff-130443061a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n-cls.pt')\n",
    "#model = YOLO('yolov8s-cls.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57092940-269d-4605-ae0a-b81ebbf199c8",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc673c4-12ff-4df8-90c5-3a3a2f2e23d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(data='./data', epochs=20, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b7e4a4a-56c3-4719-ba1d-6f4ae413a7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.173 ðŸš€ Python-3.10.11 torch-2.0.1 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6070MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1498930 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /opt/app/data/train... found 1600 images in 50 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /opt/app/data/val... found 400 images in 50 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /opt/app/data/val... 400 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:00<?, ?it/s]\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:03<00:00,  7.16it/s]\n",
      "                   all      0.782      0.952\n",
      "Speed: 1.1ms preprocess, 3.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab750023-3868-4f4a-a584-517e47a70a64",
   "metadata": {},
   "source": [
    "![Audio Classification with Computer Vision](./assets/confusion_matrix_normalized.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e49e2969-8163-45c8-9456-c098bdfe1edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7824999690055847\n",
      "0.9524999856948853\n"
     ]
    }
   ],
   "source": [
    "print(metrics.top1)\n",
    "print(metrics.top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21acc0-cce4-4406-b4f3-398d51be1bd4",
   "metadata": {},
   "source": [
    "## Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eff4c95b-8fdc-457c-b227-005bcd247946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /opt/app/data/test/helicopter.jpg: 640x640 helicopter 0.56, crying_baby 0.09, crickets 0.08, sea_waves 0.07, snoring 0.07, 3.5ms\n",
      "Speed: 4.9ms preprocess, 3.5ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Predict with the model\n",
    "pred = model('data/test/helicopter.jpg')\n",
    "\n",
    "# helicopter 0.56, crying_baby 0.09, crickets 0.08, sea_waves 0.07, snoring 0.07, 3.5ms\n",
    "# Speed: 4.9ms preprocess, 3.5ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "733151d9-01f1-429b-9f8b-9f5e60450b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /opt/app/data/test/cat.jpg: 640x640 cat 0.55, rooster 0.23, crying_baby 0.22, laughing 0.00, siren 0.00, 3.5ms\n",
      "Speed: 13.0ms preprocess, 3.5ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Predict with the model\n",
    "pred = model('data/test/cat.jpg')\n",
    "\n",
    "# cat 0.55, rooster 0.23, crying_baby 0.22, laughing 0.00, siren 0.00, 3.5ms\n",
    "# Speed: 13.0ms preprocess, 3.5ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c4cf0-68e7-4381-9e02-a022929bc816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
